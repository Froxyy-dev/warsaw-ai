# Analiza: Dlaczego Backend Zwraca 500 i Nie Przyjmuje WiadomoÅ›ci?

## ğŸ”´ Objawy

### Timeline z LogÃ³w Frontendu:
```
21:04:17.907 ğŸ“¤ Sending message to backend: 886859039
21:04:17.907 ğŸ”„ Starting auto-refresh...
21:04:22.919 ğŸ”„ Auto-refresh #1
21:04:27.919 ğŸ”„ Auto-refresh #2
21:04:32.920 ğŸ”„ Auto-refresh #3
21:04:37.920 ğŸ”„ Auto-refresh #4
21:04:42.920 ğŸ”„ Auto-refresh #5
21:04:47.920 ğŸ”„ Auto-refresh #6
21:04:47.926 âŒ Failed to send message: 500 Internal Server Error
```

### Kluczowe Obserwacje:
1. **POST /messages trwa ~30 sekund** (21:04:17 â†’ 21:04:47)
2. **Podczas tych 30 sekund**: auto-refresh co 5s prÃ³buje GET /conversations/{id}
3. **Po 30 sekundach**: POST zwraca 500 error
4. **Response**: "Internal Server Error" (HTML, nie JSON!)
5. **Wszystkie pÃ³Åºniejsze GET teÅ¼ failujÄ…** z 500

## ğŸ¯ Diagnoza

### Problem #1: Backend Nie Odpowiada na Port 8000

WczeÅ›niejsze testy pokazaÅ‚y:
```bash
$ curl http://localhost:8000/
Connection refused
```

**Backend nie dziaÅ‚a!** Albo:
- SiÄ™ wyÅ‚Ä…czyÅ‚ (crash)
- Nie uruchomiÅ‚ siÄ™ po zmianach
- Ma bÅ‚Ä…d podczas startu

### Problem #2: Zawiesza siÄ™ na `sendMessageApi()`

Frontend:
```typescript
// ChatWindow.tsx line ~166
await sendMessageApi(convId, messageContent);  // â† TUTAJ SIÄ˜ ZAWIESZA
```

To wywoÅ‚anie:
```typescript
// chatApi.ts
export const sendMessage = async (conversationId, content) => {
  const response = await api.post(
    `/chat/conversations/${conversationId}/messages`,
    { content }
  );
  return response.data;
};
```

**Axios czeka 30 sekund** na odpowiedÅº, potem dostaje 500.

### Problem #3: Backend Prawdopodobnie Crashuje PODCZAS Przetwarzania

MoÅ¼liwe scenariusze:

#### Scenariusz A: Backend Crashuje na Start (Syntax Error)
```
Nasze zmiany w chat.py lub storage_manager.py
    â†“
Backend prÃ³buje siÄ™ zrestartowaÄ‡
    â†“
Python syntax error / import error
    â†“
Uvicorn nie moÅ¼e uruchomiÄ‡ aplikacji
    â†“
Connection refused
```

**SprawdÅº:** Terminal gdzie `make run-backend` - powinien byÄ‡ czerwony traceback!

#### Scenariusz B: Backend Crashuje PODCZAS Requestu
```
Frontend: POST /messages
    â†“
Backend: Przyjmuje request
    â†“
Backend: PrÃ³buje process_user_message()
    â†“
âŒ Exception w chat_service.py / party_planner.py
    â†“
Backend: Zwraca 500 (ale uvicorn dalej dziaÅ‚a)
```

**SprawdÅº:** Terminal backendu - logi `ğŸ“¥ Received message...` i potem bÅ‚Ä…d

#### Scenariusz C: Backend "Zawiesi siÄ™" na DÅ‚ugiej Operacji
```
Frontend: POST /messages
    â†“
Backend: process_user_message() - wywoÅ‚uje LLM
    â†“
LLM Request timeout / API error
    â†“
Backend "wisi" 30+ sekund
    â†“
Timeout i zwraca 500
```

## ğŸ” Jak ZdiagnozowaÄ‡ DOKÅADNIE?

### Krok 1: SprawdÅº czy Backend w OgÃ³le DziaÅ‚a
```bash
ps aux | grep uvicorn
# JeÅ›li nic nie pokazuje â†’ backend NIE dziaÅ‚a!
```

### Krok 2: SprawdÅº Logi Startu Backendu

Terminal gdzie `make run-backend` powinien pokazaÄ‡:
```
INFO: Started server process [XXX]
INFO: Application startup complete.
```

**JeÅ›li NIE MA tego** â†’ backend siÄ™ nie uruchomiÅ‚! BÄ™dzie traceback Pythona.

### Krok 3: SprawdÅº Logi Request

JeÅ›li backend dziaÅ‚a, przy wysÅ‚aniu wiadomoÅ›ci powinny byÄ‡ logi:
```
ğŸ“¥ Received message request for conversation XXX
ğŸ” Checking if conversation XXX exists...
âœ… Conversation exists
ğŸ’¾ Creating user message...
ğŸ’¾ Saving user message to storage...
âœ… User message saved
ğŸ¤– Starting AI processing...
```

**Gdzie to siÄ™ przerywa?** Tam jest bÅ‚Ä…d!

### Krok 4: Test BezpoÅ›rednio Backendu

```bash
# Test czy backend odpowiada
curl http://localhost:8000/

# Test health endpoint
curl http://localhost:8000/api/chat/health

# JeÅ›li oba failujÄ… â†’ backend nie dziaÅ‚a
```

## ğŸ¯ MoÅ¼liwe Przyczyny (Ranked)

### 1. **Backend siÄ™ nie uruchomiÅ‚ po zmianach** (90% pewnoÅ›ci)

**Przyczyna:** Moje zmiany w `chat.py` lub `storage_manager.py` majÄ… bÅ‚Ä…d skÅ‚adniowy lub import error.

**SprawdÅº:**
```bash
cd backend
python3 -c "import routers.chat"
# JeÅ›li error â†’ to jest problem!
```

**Objawy:**
- `ps aux | grep uvicorn` â†’ nic nie pokazuje
- `curl http://localhost:8000/` â†’ Connection refused
- Terminal backendu â†’ czerwony traceback Pythona

**Fix:** Cofnij ostatnie zmiany lub napraw bÅ‚Ä…d importu.

### 2. **Backend Crashuje na `process_user_message()`** (60% pewnoÅ›ci)

**Przyczyna:** BÅ‚Ä…d w `chat_service.py` podczas:
- Tworzenia duplicate user message (zapisaliÅ›my raz w chat.py, drugi raz w chat_service.py?)
- Przetwarzania przez party_planner
- WywoÅ‚ania LLM

**Objawy:**
- Backend siÄ™ uruchamia OK
- Logi pokazujÄ…: "ğŸ“¥ Received..." â†’ "ğŸ¤– Starting AI processing..." â†’ âŒ CRASH
- 500 error dopiero po 30s

**Fix:** Dodaj try-except w `process_user_message()` z logowaniem.

### 3. **Duplicate Message Creation** (80% pewnoÅ›ci) â­ NAJPRAWDOPODOBNIEJSZE

**Przyczyna:** W `chat.py` teraz:
```python
# Linia ~113: Tworzymy user_message i zapisujemy
user_message = Message(...)
storage_manager.add_message_to_conversation(conversation_id, user_message)

# Linia ~126: WywoÅ‚ujemy chat_service
_, assistant_message = await chat_service.process_user_message(
    conversation_id,
    message_request.content  # â† Przekazujemy content, NIE message!
)
```

W `chat_service.py`:
```python
async def process_user_message(self, conversation_id, content):
    # chat_service prawdopodobnie ZNOWU tworzy user_message!
    # I prÃ³buje go zapisaÄ‡!
    # â†’ Conflict lub duplicate!
```

**Problem:** 
- chat.py: Tworzy user_message â†’ zapisuje
- chat_service.py: ZNOWU tworzy user_message â†’ prÃ³buje zapisaÄ‡
- âŒ Duplicate ID? âŒ Race condition? âŒ Validation error?

### 4. **Timeout w LLM Call** (30% pewnoÅ›ci)

LLM moÅ¼e nie odpowiadaÄ‡ i request wisi.

## ğŸ”§ Jak To NaprawiÄ‡?

### Fix #1: Najpierw SprawdÅº Czy Backend DziaÅ‚a

```bash
# Terminal 1
ps aux | grep uvicorn

# JeÅ›li nie ma procesu:
cd backend
make run-backend

# SprawdÅº czy sÄ… bÅ‚Ä™dy w terminalu!
```

### Fix #2: UsuÅ„ Duplicate Message Creation

**Problem:** `chat.py` tworzy user_message, ale `chat_service.py` prawdopodobnie teÅ¼!

**RozwiÄ…zanie A:** PrzekaÅ¼ juÅ¼ utworzony message do chat_service:
```python
# chat.py
user_message = Message(...)
storage_manager.add_message_to_conversation(conversation_id, user_message)

# PrzekaÅ¼ message, nie content!
assistant_message = await chat_service.process_user_message(
    conversation_id,
    user_message  # â† CaÅ‚y message!
)
```

**RozwiÄ…zanie B:** UsuÅ„ tworzenie message z chat.py, zostaw tylko w chat_service:
```python
# chat.py
# WywoÅ‚aj chat_service - on stworzy i zapisze WSZYSTKO
user_message, assistant_message = await chat_service.process_user_message(
    conversation_id,
    message_request.content
)
# Nie zapisuj nic tutaj - chat_service to juÅ¼ zrobiÅ‚
```

### Fix #3: Dodaj Error Handling

```python
# chat.py
try:
    _, assistant_message = await chat_service.process_user_message(...)
except Exception as e:
    logger.error(f"âŒ CRASH: {e}", exc_info=True)
    # Zapisz error message dla uÅ¼ytkownika
    error_msg = Message(...)
    storage_manager.add_message_to_conversation(conversation_id, error_msg)
    raise HTTPException(status_code=500, detail=str(e))
```

## ğŸ“Š Podsumowanie

### Co Wiemy NA PEWNO:
1. âœ… Frontend wysyÅ‚a request poprawnie
2. âœ… Next.js proxy przekazuje do backendu
3. âŒ **Backend zwraca 500 po ~30 sekundach**
4. âŒ Response to HTML "Internal Server Error" zamiast JSON
5. âŒ PÃ³Åºniejsze requesty teÅ¼ failujÄ…

### Co Musimy SprawdziÄ‡:
1. **Czy uvicorn dziaÅ‚a?** â†’ `ps aux | grep uvicorn`
2. **Czy backend siÄ™ uruchomiÅ‚?** â†’ Terminal backendu - logi
3. **Gdzie crashuje?** â†’ Logi z emoji ğŸ“¥ ğŸ” ğŸ’¾ ğŸ¤–
4. **Co jest w response?** â†’ DevTools â†’ Network â†’ kliknij failed request â†’ Response tab

### Najbardziej Prawdopodobna Przyczyna:
**Duplicate message creation** - chat.py i chat_service.py tworzÄ… user_message 2 razy!

## ğŸš€ Action Items

1. **NIE rÃ³bmy Å¼adnych zmian** (jak chciaÅ‚eÅ›)
2. **SprawdÅº terminal backendu** - skopiuj logi
3. **SprawdÅº czy uvicorn dziaÅ‚a**: `ps aux | grep uvicorn`
4. **Jak backend dziaÅ‚a** - wyÅ›lij wiadomoÅ›Ä‡ i pokaÅ¼ logi z terminala backendu (tam gdzie emoji)

## ğŸ¯ PROBLEM ZNALEZIONY! (UPDATE 21:08)

### âœ… Root Cause: Blocking Sync Call w Async Context

**User zgÅ‚osiÅ‚:** Backend psuje siÄ™ podczas przejÅ›cia do fazy venue search (po zebraniu danych uÅ¼ytkownika).

### ğŸ” Co siÄ™ dzieje krok po kroku:

```
1. UÅ¼ytkownik wysyÅ‚a ostatniÄ… informacjÄ™: "886859039" (telefon)
   â†“
2. information_gatherer.py â†’ zwraca {"type": "complete"}
   â†“
3. party_planner.py â†’ zmienia state na SEARCHING
   â†“
4. chat_service.py (linia 244) â†’ wykrywa zmianÄ™ state
   â†“
5. chat_service.py (linia 249) â†’ wywoÅ‚uje party_planner.search_venues_only()
   â†“
6. party_planner.py (linia 340) â†’ wywoÅ‚uje venue_searcher.search_venues()
   â†“
7. venue_searcher.py (linia 79) â†’ wywoÅ‚uje llm_client.send(prompt)  âš ï¸ TUTAJ!
   â†“
8. llm_client.send() to SYNC (nie async) call do Gemini API + Google Search
   â†“
9. âŒ BLOKUJE caÅ‚y FastAPI event loop na 20-30 sekund!
   â†“
10. Frontend auto-refresh prÃ³buje GET /conversations/{id} co 5s
    â†“
11. Backend nie moÅ¼e odpowiedzieÄ‡ bo wisi na llm_client.send()
    â†“
12. Po 30s: timeout lub Gemini error â†’ 500 Internal Server Error
```

### ğŸ› Kod Å¹rÃ³dÅ‚owy Problemu:

**venue_searcher.py:52-79**
```python
def search_venues(self, location: str, ...) -> VenueSearchResult:
    # âš ï¸ To jest SYNC metoda (nie async)
    try:
        logger.info(f"Searching for {count} venues...")
        prompt = self.VENUE_SEARCH_PROMPT.format(...)
        
        # âš ï¸ BLOCKING CALL - wisi 20-30 sekund!
        response = self.llm_client.send(prompt)  # â† TUTAJ SIÄ˜ BLOKUJE
        
        venues = self._parse_search_results(response, ...)
        return VenueSearchResult(venues=venues[:count], ...)
    except Exception as e:
        logger.error(f"Failed to search venues: {e}")
        return VenueSearchResult(venues=[], ...)
```

**party_planner.py:330-344**
```python
async def search_venues_only(self) -> str:
    # To jest async metoda...
    location = self.gathered_info.get("location", "Warszawa")
    
    # âš ï¸ Ale wywoÅ‚uje SYNC venue_searcher.search_venues()
    venue_results = self.venue_searcher.search_venues(
        location=location,
        query_type="lokale z salami/restauracje",
        count=3
    )  # â† Brakuje 'await' i search_venues nie jest async!
```

### âŒ Dlaczego to powoduje 500 Error:

1. **Blocking I/O w Event Loop:**
   - `llm_client.send()` to sync call do zewnÄ™trznego API (Gemini)
   - Trwa 20-30 sekund
   - **Blokuje caÅ‚y FastAPI event loop** - Å¼aden inny request nie moÅ¼e byÄ‡ obsÅ‚uÅ¼ony!

2. **Auto-refresh Colliduje:**
   - Frontend co 5s robi GET /conversations/{id}
   - Backend nie moÅ¼e odpowiedzieÄ‡ bo jest zablokowany
   - Request timeout â†’ 500 error

3. **LLM moÅ¼e teÅ¼ timeoutowaÄ‡:**
   - JeÅ›li Gemini API nie odpowiada w okreÅ›lonym czasie
   - `llm_client.send()` moÅ¼e rzuciÄ‡ exception
   - Exception propaguje do gÃ³ry â†’ 500 error

### ğŸ“Š Evidence z LogÃ³w:

```
21:04:17.907 ğŸ“¤ Sending message: 886859039     â† User wysyÅ‚a ostatniÄ… info
21:04:22.919 ğŸ”„ Auto-refresh #1               â† +5s - prÃ³ba odczytu
21:04:27.919 ğŸ”„ Auto-refresh #2               â† +10s
21:04:32.920 ğŸ”„ Auto-refresh #3               â† +15s
21:04:37.920 ğŸ”„ Auto-refresh #4               â† +20s
21:04:42.920 ğŸ”„ Auto-refresh #5               â† +25s
21:04:47.920 ğŸ”„ Auto-refresh #6               â† +30s
21:04:47.926 âŒ Failed: 500 Internal Server Error  â† CRASH po 30s!
```

**DokÅ‚adnie 30 sekund** - typowy HTTP timeout lub Gemini API timeout.

---

## ğŸ”§ Jak To NaprawiÄ‡? (Propozycje)

### Fix #1: ZmieÅ„ venue_searcher na Async (Recommended)

**venue_searcher.py:**
```python
async def search_venues(self, location: str, ...) -> VenueSearchResult:
    try:
        logger.info(f"Searching for {count} venues...")
        prompt = self.VENUE_SEARCH_PROMPT.format(...)
        
        # âœ… Async call - nie blokuje event loop!
        response = await self.llm_client.send_async(prompt)
        
        venues = self._parse_search_results(response, ...)
        return VenueSearchResult(venues=venues[:count], ...)
    except Exception as e:
        logger.error(f"Failed to search venues: {e}", exc_info=True)
        return VenueSearchResult(venues=[], ...)
```

**party_planner.py:**
```python
async def search_venues_only(self) -> str:
    location = self.gathered_info.get("location", "Warszawa")
    
    # âœ… Teraz z await!
    venue_results = await self.venue_searcher.search_venues(
        location=location,
        query_type="lokale z salami/restauracje",
        count=3
    )
```

**Wymaga:** ZaimplementowaÄ‡ `llm_client.send_async()` albo zrobiÄ‡ istniejÄ…cy `send()` async.

### Fix #2: Use run_in_executor (Alternatywa)

JeÅ›li nie moÅ¼esz zmieniÄ‡ `llm_client.send()` na async:

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def search_venues_only(self) -> str:
    location = self.gathered_info.get("location", "Warszawa")
    
    # âœ… Uruchom sync call w osobnym wÄ…tku
    loop = asyncio.get_event_loop()
    venue_results = await loop.run_in_executor(
        None,  # Uses default ThreadPoolExecutor
        self.venue_searcher.search_venues,
        location,
        "lokale z salami/restauracje",
        3
    )
```

### Fix #3: Increase Timeout + Better Error Handling

JeÅ›li async nie jest opcjÄ…, przynajmniej zwiÄ™ksz timeout i popraw error handling:

**venue_searcher.py:**
```python
def search_venues(self, location: str, ...) -> VenueSearchResult:
    try:
        logger.info(f"ğŸ” Starting venue search in {location}...")
        prompt = self.VENUE_SEARCH_PROMPT.format(...)
        
        # ZwiÄ™ksz timeout w LLMClient
        response = self.llm_client.send(prompt, timeout=60)  # 60s zamiast 30s
        
        logger.info(f"âœ… LLM responded, parsing results...")
        venues = self._parse_search_results(response, ...)
        logger.info(f"âœ… Found {len(venues)} venues")
        
        return VenueSearchResult(venues=venues[:count], ...)
        
    except TimeoutError as e:
        logger.error(f"âŒ LLM timeout during venue search: {e}")
        return VenueSearchResult(venues=[], ...)
    except Exception as e:
        logger.error(f"âŒ Venue search failed: {e}", exc_info=True)
        return VenueSearchResult(venues=[], ...)
```

### Fix #4: Save Progress Messages BEFORE Long Operations

**chat_service.py:**
```python
if state_before == PlanState.GATHERING and self.party_planner.state == PlanState.SEARCHING:
    logger.info("ğŸ” Gathering complete, executing search...")
    
    # âœ… Najpierw zapisz "starting" message
    starting_msg = Message(
        id=str(uuid.uuid4()),
        conversation_id=conversation_id,
        role=MessageRole.ASSISTANT,
        content="ğŸ” Zaczynam wyszukiwanie lokali...",
        timestamp=datetime.now()
    )
    storage_manager.add_message_to_conversation(conversation_id, starting_msg)
    logger.info("âœ… Starting message saved - frontend can see it now")
    
    # Teraz dÅ‚uga operacja
    logger.info("ğŸ¢ Step 1: Searching venues...")
    venue_response = await self.party_planner.search_venues_only()
    # ...
```

To da userowi natychmiastowy feedback Å¼e coÅ› siÄ™ dzieje.

---

## ğŸ¯ Rekomendacja

**Najlepsze rozwiÄ…zanie:** Fix #1 + Fix #4
1. ZmieÅ„ `venue_searcher.search_venues()` i `search_bakeries()` na async
2. ZmieÅ„ `llm_client.send()` na async (lub dodaj `send_async()`)
3. Dodaj progress messages PRZED dÅ‚ugimi operacjami
4. Popraw error handling z try-except i logowaniem

**Quick win (tymczasowy):** Fix #4
- Zapisz "Zaczynam wyszukiwanie..." PRZED wywoÅ‚aniem venue_searcher
- User zobaczy Å¼e coÅ› siÄ™ dzieje (auto-refresh zadziaÅ‚a)
- Potem napraw async problem

---

## ğŸ¤” Pytanie do Ciebie

**Co dalej?**
1. Chcesz Å¼ebym naprawiÅ‚ to teraz? (async + progress messages)
2. Wolisz najpierw zobaczyÄ‡ logi z backendu Å¼eby potwierdziÄ‡ diagnozÄ™?
3. Chcesz tylko quick win (progress messages) na razie?

---

**Data:** 29.11.2025 21:08  
**Status:** âœ… Root cause zidentyfikowany - blocking sync call w venue_searcher  
**Problem:** `llm_client.send()` blokuje event loop na 30s podczas venue search  
**Fix:** ZmieniÄ‡ venue_searcher + llm_client na async

