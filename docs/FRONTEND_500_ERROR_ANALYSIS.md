# Analiza bÅ‚Ä™du 500 Internal Server Error

## ğŸ”´ Problem

Frontend dostaje **500 Internal Server Error** podczas wysyÅ‚ania wiadomoÅ›ci:

```
POST http://localhost:3001/api/chat/conversations/{id}/messages
Status: 500 Internal Server Error
Response: "Internal Server Error" (HTML, nie JSON!)
Error: XML Parsing Error: syntax error
```

## ğŸ” Objawy

1. **Auto-refresh DZIAÅA** - widaÄ‡ "Auto-refresh #14" w logach
2. **GET requests dziaÅ‚ajÄ…** - odczytywanie konwersacji dziaÅ‚a
3. **POST request failuje** - wysyÅ‚anie wiadomoÅ›ci crashuje backend
4. **Backend zwraca HTML zamiast JSON** - "XML Parsing Error" oznacza Å¼e axios dostaÅ‚ HTML error page

## âœ… Co DZIAÅA

Test backendu bezpoÅ›rednio (port 8000) pokazuje Å¼e:
- âœ… Tworzenie konwersacji: OK
- âœ… WysyÅ‚anie wiadomoÅ›ci: OK  
- âœ… Generowanie odpowiedzi AI: OK
- âœ… Zapisywanie do pliku: OK

**Backend SAM W SOBIE dziaÅ‚a poprawnie!**

## âŒ Co NIE DZIAÅA

Problem jest w **komunikacji Frontend â†’ Next.js Proxy â†’ Backend**:

```
Frontend (3001) â†’ Next.js Proxy â†’ Backend (8000)
                      â†“
                   500 ERROR
```

## ğŸ¯ Prawdopodobne Przyczyny

### 1. **Race Condition w Backend Storage**

Podczas gdy backend przetwarza jednÄ… wiadomoÅ›Ä‡ (LLM call, venue search, voice agent), 
frontend wysyÅ‚a auto-refresh requesty co 2 sekundy.

```
Timeline:
T+0s:  Frontend: POST /messages (wysyÅ‚a "test")
T+0s:  Backend:  Zaczyna przetwarzaÄ‡ (chat_service.py)
T+2s:  Frontend: GET /conversations/{id} (auto-refresh #1)
T+2s:  Backend:  âŒ CRASH - prÃ³buje czytaÄ‡ plik podczas gdy inny wÄ…tek zapisuje
T+4s:  Frontend: GET /conversations/{id} (auto-refresh #2)  
T+4s:  Backend:  âŒ CRASH - backend juÅ¼ nie odpowiada
```

**Kod problematyczny:**

`backend/routers/chat.py` linia ~114-129:
```python
# Process message and generate AI response
_, assistant_message = await chat_service.process_user_message(
    conversation_id,
    message_request.content
)

# Save assistant message
storage_manager.add_message_to_conversation(
    conversation_id,
    assistant_message
)
```

`backend/storage_manager.py` - brak lockowania podczas I/O:
- WÄ…tek 1: Pisze do pliku (POST /messages)
- WÄ…tek 2: Czyta z pliku (GET /conversations/{id}) - auto-refresh
- âŒ File lock conflict!

### 2. **Backend Crashuje ale Uvicorn Nie Pokazuje Traceback**

MoÅ¼liwe Å¼e:
- Exception jest Å‚apany gdzieÅ› wyÅ¼ej i zwracany jako 500 bez logu
- Uvicorn w trybie reload nie pokazuje wszystkich errorÃ³w
- Problem jest w async code i exception ginie

### 3. **Next.js Proxy Timeout**

Next.js proxy moÅ¼e mieÄ‡ timeout na dÅ‚ugie requesty (LLM moÅ¼e trwaÄ‡ 10-30s).

## ğŸ”§ RozwiÄ…zania

### RozwiÄ…zanie 1: Dodaj File Locking (NAJLEPSZE)

```python
# backend/storage_manager.py

import fcntl  # POSIX file locking

def save_conversation(self, conversation: Conversation) -> bool:
    lock = self._get_lock(conversation.id)
    file_path = self._get_file_path(conversation.id)
    
    try:
        with lock:
            # OtwÃ³rz plik z lockiem
            with open(file_path, 'w') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)  # Exclusive lock
                json.dump(conversation.model_dump(mode='json'), f, indent=2)
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)  # Unlock
        return True
    except Exception as e:
        logger.error(f"Failed to save: {e}")
        return False
```

### RozwiÄ…zanie 2: WyÅ‚Ä…cz Auto-Refresh Podczas POST

```typescript
// frontend/src/components/ChatWindow.tsx

const handleSendMessage = async (e: React.FormEvent) => {
    // ...
    
    // WyÅ‚Ä…cz auto-refresh PRZED wysÅ‚aniem
    setIsSearching(false);
    
    try {
        await sendMessageApi(convId, messageContent);
        
        // Poczekaj trochÄ™ przed wÅ‚Ä…czeniem auto-refresh
        await new Promise(resolve => setTimeout(resolve, 2000));
        
        // Teraz wÅ‚Ä…cz auto-refresh
        setIsSearching(true);
    } catch (err) {
        // ...
    }
};
```

### RozwiÄ…zanie 3: Lepsze Error Handling w Backend

```python
# backend/routers/chat.py

@router.post("/conversations/{conversation_id}/messages", response_model=Message)
async def send_message(conversation_id: str, message_request: MessageRequest):
    try:
        # ... existing code ...
    except Exception as e:
        logger.error(f"CRITICAL ERROR in send_message: {e}", exc_info=True)
        # ZwrÃ³Ä‡ szczegÃ³Å‚y bÅ‚Ä™du dla debugowania
        raise HTTPException(
            status_code=500,
            detail={"error": str(e), "type": type(e).__name__}
        )
```

### RozwiÄ…zanie 4: ZwiÄ™ksz Timeout Next.js Proxy

```javascript
// frontend/next.config.js

const nextConfig = {
  async rewrites() {
    return [{
      source: '/api/:path*',
      destination: 'http://localhost:8000/api/:path*',
    }];
  },
  // ZwiÄ™ksz timeout dla dÅ‚ugich requestÃ³w
  serverRuntimeConfig: {
    timeout: 300000  // 5 minut
  }
};
```

### RozwiÄ…zanie 5: UÅ¼yj Queue dla DÅ‚ugich ZadaÅ„ (PRODUKCYJNE)

Zamiast czekaÄ‡ na LLM w request:

```
1. Frontend: POST /messages â†’ Backend: Zwraca 202 Accepted (natychmiast)
2. Backend: Przetwarza w tle (worker/queue)
3. Frontend: Auto-refresh sprawdza czy juÅ¼ gotowe
```

## ğŸ¯ Rekomendacja: Co ZrobiÄ‡ TERAZ

**Dla POC (quickest fix):**

1. **Dodaj wiÄ™cej logÃ³w w backend:**
```bash
cd backend
# Edytuj chat.py, dodaj try-except z logowaniem
```

2. **Uruchom backend w verbose mode:**
```bash
uvicorn main:app --reload --log-level debug
```

3. **SprawdÅº logi podczas wysyÅ‚ania wiadomoÅ›ci** - powinny pojawiÄ‡ siÄ™ czerwone tracebacki

4. **WyÅ‚Ä…cz auto-refresh podczas POST** (tymczasowo):
```typescript
// W ChatWindow.tsx - ustaw dÅ‚uÅ¼szy interval
}, 5000); // 5 sekund zamiast 2
```

## ğŸ“Š Debug Checklist

Gdy wyÅ›lesz wiadomoÅ›Ä‡, sprawdÅº:

- [ ] Terminal z backendem (uvicorn) - czy sÄ… czerwone errory?
- [ ] Terminal z frontendem (npm run dev) - czy sÄ… errory?
- [ ] DevTools â†’ Network â†’ kliknij failed request â†’ Preview - co dokÅ‚adnie jest w response?
- [ ] SprawdÅº plik JSON konwersacji - czy jest uszkodzony?

## ğŸ”¬ Test Izolowany

ZrÃ³b to aby potwierdziÄ‡ teoriÄ™:

```bash
# Terminal 1: WyÅ›lij wiadomoÅ›Ä‡ (bÄ™dzie trwaÄ‡ 5-10s)
curl -X POST http://localhost:8000/api/chat/conversations/{ID}/messages \
  -H "Content-Type: application/json" \
  -d '{"content":"test"}' &

# Terminal 2: Podczas gdy backend przetwarza, sprÃ³buj odczytaÄ‡
sleep 2
curl http://localhost:8000/api/chat/conversations/{ID}

# Czy dostaniesz 500?
```

JeÅ›li TAK â†’ to race condition w storage!
JeÅ›li NIE â†’ problem jest gdzie indziej.

## ğŸ“ Next Steps

1. Przeczytaj ten dokument
2. Zbierz logi z backendu (terminal gdzie uvicorn)
3. Zastosuj RozwiÄ…zanie 2 (wyÅ‚Ä…cz auto-refresh podczas POST)
4. JeÅ›li problem persist â†’ zastosuj RozwiÄ…zanie 1 (file locking)

---

**Data analizy:** 29.11.2025  
**Status:** Backend dziaÅ‚a, problem w race condition podczas concurrent requests  
**Priorytet:** HIGH - blokuje podstawowÄ… funkcjonalnoÅ›Ä‡

